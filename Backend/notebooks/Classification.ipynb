{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = 'titanic/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "\n",
    "def read_file(path, limit_n_rows=None):\n",
    "    filename, ext = splitext(path)\n",
    "    if ext == '.csv':\n",
    "        return pd.read_csv(path, nrows=limit_n_rows)\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        return pd.read_excel(path, nrows=limit_n_rows)\n",
    "    else:\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = read_file(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.28</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.10</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  Fare Cabin Embarked\n",
       "0            1         0       3                            Braund, Mr. Owen Harris    male 22.00      1      0         A/5 21171  7.25   NaN        S\n",
       "1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female 38.00      1      0          PC 17599 71.28   C85        C\n",
       "2            3         1       3                             Heikkinen, Miss. Laina  female 26.00      0      0  STON/O2. 3101282  7.92   NaN        S\n",
       "3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female 35.00      1      0            113803 53.10  C123        S\n",
       "4            5         0       3                           Allen, Mr. William Henry    male 35.00      0      0            373450  8.05   NaN        S"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()[c for c, col in enumerate(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c, col in enumerate(dataset.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Survived'\n",
    "ID_COLUMN = 'PassengerId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from enum import Enum\n",
    "\n",
    "UNKNOWN_SONYNOMS = [\"unknown\", \"n/a\", \"NaN\", \"\"]\n",
    "\n",
    "class ProblemTypes(Enum):\n",
    "    BINARY_CLASSIFICATION = 1\n",
    "    MULTI_LABEL_CLASSIFICATION = 2\n",
    "    REGRESSION = 3\n",
    "    CLASSIFICATION = 4\n",
    "    UNKNOWN = 5\n",
    "\n",
    "\n",
    "def handle_nans(iterable): return [np.nan if str(i).lower().strip() in UNKNOWN_SONYNOMS else i for i in iterable]                \n",
    "def contains_string(iterable): return any([type(key) == 'str' for key, count in iterable])\n",
    "def n_or_more_similar(iterable): return all([count > 1 for key, count in iterable])\n",
    "def only_2_classes(iterable): return len([i for i in iterable if i is not np.nan])\n",
    "def dtype_share(iterable, dtype, threshold=0.9): \n",
    "    success_count = 0\n",
    "    for i in iterable:\n",
    "        try:\n",
    "            dtype(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            success_count += 1\n",
    "    return success_count / len(iterable)\n",
    "\n",
    "def guess_problem_type(df, target_column):\n",
    "    labels = df[target_column].copy()\n",
    "    labels = handle_nans(labels)\n",
    "    c = Counter(labels)    \n",
    "    top5 = c.most_common()[:5]\n",
    "\n",
    "    if contains_string(top5) and n_or_more_similar(top5):\n",
    "        if only_2_classes(top5):\n",
    "            return ProblemTypes.BINARY_CLASSIFICATION\n",
    "        else:\n",
    "            return ProblemTypes.MULTI_LABEL_CLASSIFICATION\n",
    "    elif dtype_share(top5.keys(), float): \n",
    "        return ProblemTypes.REGRESSION\n",
    "    else:\n",
    "        return ProblemTypes.UNKNOWN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problem_type = guess_problem_type(dataset, TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ProblemTypes.REGRESSION: 3>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse label and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({\n",
    "    \"label\": [5, 10, 4.3, 30, 40, \"a\", 3, 3, 3, \"b\", np.nan],\n",
    "    \"id\": np.arange(11)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABEL_ASSESSMENT = {\n",
    "    \"nan_share\": 0,\n",
    "    \"CLASSIFICATION\": {\n",
    "        \"number_of_categories\": 0        \n",
    "    },\n",
    "    \"REGRESSION\": {\n",
    "        \"not_a_number_share\": 0                \n",
    "    }  \n",
    "}\n",
    "\n",
    "ID_ASSESSMENT = {\n",
    "    \"nan_share\": 0    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_label_and_id(label_column, id_column, df, \n",
    "                   problem_type, label_assessment, id_assessment):\n",
    "    \"\"\" \n",
    "    Assess if there are any issues with the labelled data column\n",
    "    \"\"\"\n",
    "    for col in [label_column, id_column]:\n",
    "        df[col] = handle_nans(df[col])\n",
    "    label_assessment[\"nan_share\"] = df[label_column].isnull().sum() / len(df[label_column])\n",
    "    id_assessment[\"nan_share\"] = df[id_column].isnull().sum() / len(df[id_column])\n",
    "    if problem_type == ProblemTypes.CLASSIFICATION:\n",
    "        label_assessment[problem_type.name][\"number_of_categories\"] = len(df[label_column].dropna().unique())\n",
    "    if problem_type == ProblemTypes.REGRESSION:\n",
    "        label_assessment[problem_type.name][\"not_a_number_share\"] = dtype_share(df[label_column], float)\n",
    "    return {\n",
    "        \"label\": label_assessment,\n",
    "        \"id\": id_assessment\n",
    "    }\n",
    "\n",
    "assessmenet = evaluate_label(\"label\", \"id\", sample_df, ProblemTypes.REGRESSION, LABEL_ASSESSMENT, ID_ASSESSMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': {'nan_share': 0.0},\n",
       " 'label': {'CLASSIFICATION': {'number_of_categories': 0},\n",
       "  'REGRESSION': {'not_a_number_share': 0.8181818181818182},\n",
       "  'nan_share': 0.090909090909090912}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessmenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_DTYPES = [\"object\", \"bool\"]\n",
    "def get_categorical_features(df, threshold=0.5):\n",
    "    return [c for c in df if df[c].dtype in CATEGORICAL_DTYPES]\n",
    "\n",
    "def find_rare_features(df1, df2, threshold=0.05):    \n",
    "    df_cat = pd.concat([df1, df2])\n",
    "    total_count = len(df_cat)\n",
    "    feature_sums = df_cat.sum()\n",
    "    return feature_sums[feature_sums / total_count < threshold].index.tolist()\n",
    "\n",
    "def add_datepart(df, date_column):    \n",
    "    df[\"Year_{}\".format(date_column)] = df[date_column].dt.year\n",
    "    df[\"Month_{}\".format(date_column)] = df[date_column].dt.month\n",
    "    df[\"Week_{}\".format(date_column)] = df[date_column].dt.week\n",
    "    df[\"Day_{}\".format(date_column)] = df[date_column].dt.day\n",
    "    df.drop([date_column], axis=1, inplace=True)\n",
    "\n",
    "def convert_timestamp(df):\n",
    "    df = df.copy()\n",
    "    df = df.apply(lambda col: pd.to_datetime(col, errors='ignore') \n",
    "          if col.dtypes == object \n",
    "          else col, \n",
    "          axis=0)\n",
    "    for col in df.select_dtypes(include=[np.datetime64]):\n",
    "        print(col)\n",
    "        add_datepart(df, col)\n",
    "    return df\n",
    "\n",
    "def preprocess_features(df):\n",
    "    return convert_timestamp(df)\n",
    "\n",
    "def preprocess_labels(ds, apply_log=False):\n",
    "    if apply_log: ds = ds.apply(np.log)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def _do_grid_search(x, y, model, params, n_folds=5):\n",
    "    gs = GridSearchCV(estimator=model, param_grid=params, verbose=5)\n",
    "    gs.fit(x, y)\n",
    "    print(\"Best\", gs.best_params_, gs.best_score_, gs.grid_scores_)\n",
    "    return gs.best_estimator_\n",
    "\n",
    "\n",
    "def train_and_fit(df, parameters, target_column, \n",
    "                  id_column, test_size=0.2):\n",
    "    \n",
    "    # Test, train split\n",
    "    df = df.copy()\n",
    "    \n",
    "    categorical_features = get_categorical_features(df)\n",
    "    lb = LabelBinarizer()\n",
    "    for c in categorical_features:        \n",
    "        df[c] = lb.fit_transform(df[c].fillna(0)) \n",
    "    \n",
    "    y = df[target_column].values\n",
    "    df.drop([id_column, target_column], inplace=True, axis=1)\n",
    "    x = df.values\n",
    "    x, x_val, y, y_val = train_test_split(x, y, test_size=test_size, random_state=42)          \n",
    "    \n",
    "    # LightGBM data containers       \n",
    "    train_data = lgb.Dataset(x, y)\n",
    "    val_data = lgb.Dataset(x_val, y_val)\n",
    "    clf_best = lgb.train(parameters,\n",
    "                         train_data,\n",
    "                         valid_sets=val_data,\n",
    "                         num_boost_round=5000)\n",
    "\n",
    "    return clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId   446.00\n",
       "Survived        0.00\n",
       "Pclass          3.00\n",
       "Age            28.00\n",
       "SibSp           0.00\n",
       "Parch           0.00\n",
       "Fare           14.45\n",
       "dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.median()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RS=1\n",
    "np.random.seed(RS)\n",
    "ROUNDS = 1500 # 1300,1400 all works fine\n",
    "regression_parameters = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01 , #small learn rate, large number of iterations\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 2 ** 5,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': RS,\n",
    "    'feature_fraction': 0.7,\n",
    "    'feature_fraction_seed': RS,\n",
    "    'max_bin': 100,\n",
    "    'max_depth': 7,\n",
    "    'num_rounds': ROUNDS,\n",
    "}\n",
    "\n",
    "classification_parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01 , #small learn rate, large number of iterations\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 2 ** 5,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': RS,\n",
    "    'feature_fraction': 0.7,\n",
    "    'feature_fraction_seed': RS,\n",
    "    'max_bin': 100,\n",
    "    'max_depth': 7,\n",
    "    'num_rounds': ROUNDS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "def select_model(problem_type):\n",
    "    return {\n",
    "        ProblemTypes.BINARY_CLASSIFICATION: GradientBoostingClassifier,\n",
    "        ProblemTypes.MULTI_LABEL_CLASSIFICATION: GradientBoostingClassifier,\n",
    "        ProblemTypes.REGRESSION: GradientBoostingRegressor      \n",
    "    }[problem_type]\n",
    "\n",
    "def create_model(df, test_df, target_column, id_column):\n",
    "    problem_type = guess_problem_type(df, target_column)\n",
    "    model = select_model(problem_type)()\n",
    "    return train_and_fit(\n",
    "        model=model,\n",
    "        df=df,        \n",
    "        kaggle_test_df=test_dataset,\n",
    "        parameters=parameters,\n",
    "        target_column=target_column,\n",
    "        id_column=id_column,\n",
    "        nvl_strategy=\"median\",\n",
    "        do_grid=False,\n",
    "        apply_imbalance=False,\n",
    "        apply_log=True,\n",
    "        remove_outliers=True)\n",
    "\n",
    "def create_classification_model(df, target_column, id_column, parameters):\n",
    "    return train_and_fit(\n",
    "        df=df,        \n",
    "        parameters=parameters,\n",
    "        target_column=target_column,\n",
    "        id_column=id_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (0                0\n1              C85\n2                0\n3             C123\n4                0\n5                0\n6              E46\n7                0\n8                0\n9                0\n10              G6\n11            C103\n12               0\n13               0\n14               0\n15               0\n16               0\n17               0\n18               0\n19               0\n20               0\n21             D56\n22               0\n23              A6\n24               0\n25               0\n26               0\n27     C23 C25 C27\n28               0\n29               0\n30               0\n31             B78\n32               0\n33               0\n34               0\n35               0\n36               0\n37               0\n38               0\n39               0\n40               0\n41               0\n42               0\n43               0\n44               0\n45               0\n46               0\n47               0\n48               0\n49               0\n          ...     \n841              0\n842              0\n843              0\n844              0\n845              0\n846              0\n847              0\n848              0\n849            C92\n850              0\n851              0\n852              0\n853            D28\n854              0\n855              0\n856              0\n857            E17\n858              0\n859              0\n860              0\n861              0\n862            D17\n863              0\n864              0\n865              0\n866              0\n867            A24\n868              0\n869              0\n870              0\n871            D35\n872    B51 B53 B55\n873              0\n874              0\n875              0\n876              0\n877              0\n878              0\n879            C50\n880              0\n881              0\n882              0\n883              0\n884              0\n885              0\n886              0\n887            B42\n888              0\n889           C148\n890              0\nName: Cabin, Length: 891, dtype: object,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-4f0f1b323504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                         \u001b[0mTARGET_COLUMN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         \u001b[0mID_COLUMN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                         classification_parameters)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-183-6a02f38ece7d>\u001b[0m in \u001b[0;36mcreate_classification_model\u001b[0;34m(df, target_column, id_column, parameters)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtarget_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         id_column=id_column)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-a3c483713693>\u001b[0m in \u001b[0;36mtrain_and_fit\u001b[0;34m(df, parameters, target_column, id_column, test_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mikkeld/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mikkeld/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mikkeld/anaconda/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (0                0\n1              C85\n2                0\n3             C123\n4                0\n5                0\n6              E46\n7                0\n8                0\n9                0\n10              G6\n11            C103\n12               0\n13               0\n14               0\n15               0\n16               0\n17               0\n18               0\n19               0\n20               0\n21             D56\n22               0\n23              A6\n24               0\n25               0\n26               0\n27     C23 C25 C27\n28               0\n29               0\n30               0\n31             B78\n32               0\n33               0\n34               0\n35               0\n36               0\n37               0\n38               0\n39               0\n40               0\n41               0\n42               0\n43               0\n44               0\n45               0\n46               0\n47               0\n48               0\n49               0\n          ...     \n841              0\n842              0\n843              0\n844              0\n845              0\n846              0\n847              0\n848              0\n849            C92\n850              0\n851              0\n852              0\n853            D28\n854              0\n855              0\n856              0\n857            E17\n858              0\n859              0\n860              0\n861              0\n862            D17\n863              0\n864              0\n865              0\n866              0\n867            A24\n868              0\n869              0\n870              0\n871            D35\n872    B51 B53 B55\n873              0\n874              0\n875              0\n876              0\n877              0\n878              0\n879            C50\n880              0\n881              0\n882              0\n883              0\n884              0\n885              0\n886              0\n887            B42\n888              0\n889           C148\n890              0\nName: Cabin, Length: 891, dtype: object,)"
     ]
    }
   ],
   "source": [
    "clf_best = create_classification_model(dataset,                                         \n",
    "                                        TARGET_COLUMN, \n",
    "                                        ID_COLUMN,\n",
    "                                        classification_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-cbd563a9c245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price_doc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lgb_mik.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf_best' is not defined"
     ]
    }
   ],
   "source": [
    "predict=clf_best.predict(test_X)\n",
    "predict=np.exp(predict)\n",
    "output=pd.DataFrame({'id':test_ids,'price_doc':predict})\n",
    "output.to_csv('lgb_mik.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y_pred), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = clf_best.predict(test_X)\n",
    "test_preds = np.exp(test_preds)\n",
    "test_rmsle = rmsle(test_y, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45879505773826001"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('/Users/mikkeld/ai-for-analysts/datasets/binary-classification/sberbank/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(test_df):\n",
    "    test_ids = test_df[ID_COLUMN]\n",
    "    test_df = test_df.drop([ID_COLUMN], axis=1)\n",
    "    test_df = preprocess_features(test_df)\n",
    "    test_preds = clf_best.predict(test_df)\n",
    "    test_preds = np.exp(test_preds)\n",
    "    output =  pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"price_doc\": test_preds\n",
    "    })    \n",
    "    output.to_csv('lgb_mik.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,TimeSeriesSplit\n",
    "from sklearn import model_selection, preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn import model_selection, preprocessing\n",
    "import pdb\n",
    "\n",
    "def process(train,test):\n",
    "    RS=1\n",
    "    np.random.seed(RS)\n",
    "    ROUNDS = 1500 # 1300,1400 all works fine\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting': 'gbdt',\n",
    "            'learning_rate': 0.01 , #small learn rate, large number of iterations\n",
    "            'verbose': 0,\n",
    "            'num_leaves': 2 ** 5,\n",
    "            'bagging_fraction': 0.95,\n",
    "            'bagging_freq': 1,\n",
    "            'bagging_seed': RS,\n",
    "            'feature_fraction': 0.7,\n",
    "            'feature_fraction_seed': RS,\n",
    "            'max_bin': 100,\n",
    "            'max_depth': 7,\n",
    "            'num_rounds': ROUNDS,\n",
    "        }\n",
    "    #Remove the bad prices as suggested by Radar\n",
    "    train=train[(train.price_doc>1e6) & (train.price_doc!=2e6) & (train.price_doc!=3e6)]\n",
    "    #train.loc[(train.product_type=='Investment') & (train.build_year<2000),'price_doc']*=0.9 \n",
    "    #train.loc[train.product_type!='Investment','price_doc']*=0.969 #Louis/Andy's magic number\n",
    "    test = pd.read_csv('/Users/mikkeld/ai-for-analysts/datasets/binary-classification/sberbank/test.csv',parse_dates=['timestamp'])\n",
    "\n",
    "  \n",
    "    id_test = test.id\n",
    "    times=pd.concat([train.timestamp,test.timestamp])\n",
    "    num_train=train.shape[0]\n",
    "    y_train = train[\"price_doc\"]\n",
    "    train.drop(['price_doc'],inplace=True,axis=1)\n",
    "    da=pd.concat([train,test])\n",
    "    da['na_count']=da.isnull().sum(axis=1)\n",
    "    df_cat=None\n",
    "    to_remove=[]\n",
    "    for c in da.columns:\n",
    "        if da[c].dtype=='object':\n",
    "            oh=pd.get_dummies(da[c],prefix=c)\n",
    "            if df_cat is None:\n",
    "                df_cat=oh\n",
    "            else:\n",
    "                df_cat=pd.concat([df_cat,oh],axis=1)\n",
    "            to_remove.append(c)\n",
    "    da.drop(to_remove,inplace=True,axis=1)\n",
    "\n",
    "    #Remove rare features,prevent overfitting\n",
    "    to_remove=[]\n",
    "    if df_cat is not None:\n",
    "        sums=df_cat.sum(axis=0)\n",
    "        to_remove=sums[sums<200].index.values\n",
    "        df_cat=df_cat.loc[:,df_cat.columns.difference(to_remove)]\n",
    "        da = pd.concat([da, df_cat], axis=1)\n",
    "    x_train=da[:num_train].drop(['timestamp','id'],axis=1)\n",
    "    x_test=da[num_train:].drop(['timestamp','id'],axis=1)\n",
    "    #Log transformation, boxcox works better.\n",
    "    y_train=np.log(y_train)\n",
    "    train_lgb=lgb.Dataset(x_train,y_train)\n",
    "    model=lgb.train(params,train_lgb,num_boost_round=ROUNDS)\n",
    "    predict=model.predict(x_test)\n",
    "    predict=np.exp(predict)\n",
    "    return predict,id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikkeld/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mikkeld/anaconda/lib/python3.5/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/mikkeld/ai-for-analysts/datasets/binary-classification/sberbank/train.csv', parse_dates=['timestamp'])\n",
    "test = pd.read_csv('/Users/mikkeld/ai-for-analysts/datasets/binary-classification/sberbank/test.csv', parse_dates=['timestamp'])\n",
    "predict,id_test=process(train,test)\n",
    "output=pd.DataFrame({'id':id_test,'price_doc':predict})\n",
    "output.to_csv('lgb3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
